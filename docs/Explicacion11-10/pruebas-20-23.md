
# üß™ Pruebas del Issues #20 al #23 (Etapa 4 - Sincronizaci√≥n de datos (eventos y transacciones))

A continuaci√≥n se detallan las pruebas **reales** que pod√©s mostrar en vivo desde Postman.
- Levantar Backend con ./mvnw
- Levantar Proxy con ./boot.sh

## Issues
- Integraci√≥n del backend con el proxy y sincronizaci√≥n local de eventos #20
- Baja l√≥gica de eventos eliminados en la c√°tedra #21
- Sincronizaci√≥n de asientos del evento #22
- Integraci√≥n con Redis para estado de asientos en tiempo real #23

---

## üîπ 1. Probar sincronizaci√≥n manual  (#20 - #21 - #22)

### En Postman  
- Backend/Admin/admin-sync-evento
- http://localhost:8080/api/admin/sync-eventos
- Devuelve: 204 No Content

### Que hace esta prueba?
Esta prueba demuestra todo el flujo de sincronizaci√≥n completa:

- Que el endpoint admin del backend existe y funciona: POST /api/admin/sync-eventos (#20).
- Que el backend llama al proxy, el proxy llama a la c√°tedra, y el backend:
    - trae los eventos reales,
    - los guarda/actualiza en PostgreSQL (Issue #20),
    - aplica reglas como la hora por defecto cuando falta (Issue #20),
    - y maneja el campo externalId y la l√≥gica de activos/inactivos (Issue #21).

- Que, por cada evento, se dispara la sincronizaci√≥n de asientos:
    - el backend llama al proxy /eventos/{id}/asientos,
    - el proxy consulta Redis remoto,
    - el backend borra los asientos locales previos y regenera toda la matriz de asientos seg√∫n lo que env√≠a la c√°tedra (Issue #22).

En resumen: con una sola llamada desde Postman est√°s probando que:
1. backend ‚Üî proxy ‚Üî c√°tedra est√°n bien conectados.
2. Se sincronizan eventos.
3. Se sincronizan asientos.
4. Y que todo queda persistido en mi propia base de datos.

### Terminal del Backend
```
DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
DispatcherServlet        : Completed initialization in 1 ms
AdminSyncResource        : [Admin-Sync] Solicitud manual de sincronizaci√≥n de eventos.
EventoSyncService        : üîÑ [Sync-Eventos] Iniciando sincronizaci√≥n de eventos contra proxy...
ProxyService             : üåê [Proxy-Backend] GET /eventos
ProxyService             : üì© [Proxy-Backend] Respuesta OK /eventos (bytes=3585)
EventoSyncService        : üì• [Sync-Eventos] Eventos recibidos desde proxy: 5 evento(s).

EventoSyncService        : ‚ôªÔ∏è [Sync-Eventos] Actualizando evento existente (id=1001, externalId=1) ‚Üí Conferencia Nerd!
EventoSyncService        : ‚ö†Ô∏è [Sync-Eventos] El evento 1 no tiene hora en el proxy. Se asigna 00:00.
EventoSyncService        : üíæ [DB] Evento guardado ‚Üí idLocal=1001, externalId=1, titulo=Conferencia Nerd!
AsientoSyncService       : üîÑ [Sync-Asientos] Iniciando sincronizaci√≥n de asientos para evento local id=1001 (externalId=1)
ProxyService             : üåê [Proxy-Backend] GET /eventos/1/asientos
ProxyService             : üì© [Proxy-Backend] Respuesta OK /eventos/1/asientos (bytes=2177)
AsientoSyncService       : üßπ [Sync-Asientos] Asientos previos eliminados para evento idLocal=1001 ‚Üí 0 asiento(s) borrado(s).
AsientoSyncService       : ‚úÖ [Sync-Asientos] Evento idLocal=1001 (externalId=1) ‚Üí Asientos sincronizados: 38 creados, 0 actualizados.

EventoSyncService        : ‚úÖ [Sync-Eventos] Sincronizaci√≥n de eventos finalizada correctamente.
AdminSyncResource        : [Admin-Sync] Sincronizaci√≥n manual finalizada.

```

### Explicaci√≥n Logs Backend

#### Versi√≥n resumida

Cuando llamo a /api/admin/sync-eventos se dispara EventoSyncService, que llama al proxy, trae 5 eventos reales y los guarda en Postgres. 

Despu√©s, por cada evento, se dispara AsientoSyncService, que va al proxy, lee los asientos de Redis y regenera toda la matriz de asientos local. 

Si el proxy no tiene asientos para un evento, limpio los locales y lo dejo sin asientos. 

#### üü¶ Arranque del endpoint admin y cierre de de la sincronizaci√≥n (#20)

- **DispatcherServlet**: Spring inicializa el controlador REST que va a atender la request. (Infraestructura, no es de un issue puntual.)
- **AdminSyncResource**: Entr√≥ al endpoint POST /api/admin/sync-eventos. (prueba que el endpoint administrativo existe y est√° funcionando)
```
DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
DispatcherServlet        : Completed initialization in 1 ms
AdminSyncResource        : [Admin-Sync] Solicitud manual de sincronizaci√≥n de eventos.

EventoSyncService        : ‚úÖ [Sync-Eventos] Sincronizaci√≥n de eventos finalizada correctamente.
AdminSyncResource        : [Admin-Sync] Sincronizaci√≥n manual finalizada.
```

#### üü© Inicio de la sincronizaci√≥n de eventos (#20)

- **üîÑ [Sync-Eventos]**: El servicio de sync arranca y marca el inicio del flujo backend ‚Üí proxy.
- **üåê [Proxy-Backend]**: El backend llama al proxy (GET /api/proxy/eventos) usando el WebClient configurado.
- **üì© [Proxy-Backend]**: El proxy respondi√≥ OK con ~3.5 KB de eventos reales. Demuestra que el proxy est√° levantado, la URL y el token son correctos.
- **üì• [Sync-Eventos]**: Se deserializa el JSON y se cuenta cu√°ntos eventos llegaron.
```
EventoSyncService        : üîÑ [Sync-Eventos] Iniciando sincronizaci√≥n de eventos contra proxy...
ProxyService             : üåê [Proxy-Backend] GET /eventos
ProxyService             : üì© [Proxy-Backend] Respuesta OK /eventos (bytes=3585)
EventoSyncService        : üì• [Sync-Eventos] Eventos recibidos desde proxy: 5 evento(s).
```

#### üü® Actualizaci√≥n de cada evento + reglas especiales (#20 - #21)
- **‚ôªÔ∏è [Sync-Eventos]**: El evento ya exist√≠a en la BD, as√≠ que se actualiza en lugar de crearlo.
- **‚ö†Ô∏è [Sync-Eventos]**: Regla de negocio: si la c√°tedra no manda hora, se usa un valor por defecto (00:00). Sirve para mostrar que el backend no se rompe con datos incompletos.
- **üíæ [DB] Evento guardado**: Confirma que el evento se guardo (persisti√≥) en PostgreSQL.
```
EventoSyncService        : ‚ôªÔ∏è [Sync-Eventos] Actualizando evento existente (id=1001, externalId=1) ‚Üí Conferencia Nerd!
EventoSyncService        : ‚ö†Ô∏è [Sync-Eventos] El evento 1 no tiene hora en el proxy. Se asigna 00:00.
EventoSyncService        : üíæ [DB] Evento guardado ‚Üí idLocal=1001, externalId=1, titulo=Conferencia Nerd!
```
üëâ Este mismo patr√≥n se repite para los eventos 2, 3, 4 y 5.

#### üüß Sincronizaci√≥n de asientos por cada evento (#22)
- **üîÑ [Sync-Asientos]**: Al terminar de guardar el evento, se dispara la sincronizaci√≥n de sus asientos.
- **üåê [Proxy-Backend]**: El backend llama al proxy para obtener el estado de asientos de ese evento.
- **üì© [Proxy-Backend]**: El proxy respondi√≥ OK y llega el JSON de asientos desde Redis (v√≠a proxy).
- **üßπ [Sync-Asientos]**: Se borran los asientos locales previos del evento (regeneraci√≥n completa). Ac√° fueron 0 porque era la primera vez.
- **‚úÖ [Sync-Asientos]**: Se recre√≥ la matriz de asientos en base a lo que devolvi√≥ la c√°tedra.
Demuestra:
- que el JSON remoto se parse√≥ bien (ProxyEstadoAsientosResponse / ProxyAsientoDTO),
- que se persistieron asientos en Postgres.
```
AsientoSyncService       : üîÑ [Sync-Asientos] Iniciando sincronizaci√≥n de asientos para evento local id=1001 (externalId=1)
ProxyService             : üåê [Proxy-Backend] GET /eventos/1/asientos
ProxyService             : üì© [Proxy-Backend] Respuesta OK /eventos/1/asientos (bytes=2177)
AsientoSyncService       : üßπ [Sync-Asientos] Asientos previos eliminados para evento idLocal=1001 ‚Üí 0 asiento(s) borrado(s).
AsientoSyncService       : ‚úÖ [Sync-Asientos] Evento idLocal=1001 (externalId=1) ‚Üí Asientos sincronizados: 38 creados, 0 actualizados.
```

#### üü™ Casos donde el proxy devuelve lista vac√≠a (Issue #22)
- **‚ÑπÔ∏è [Sync-Asientos]**: El proxy respondi√≥ correctamente, pero con lista vac√≠a de asientos.
- **‚ö†Ô∏è [Sync-Asientos]**: Regla de negocio: si la c√°tedra no tiene asientos para ese evento, tu backend limpia los que pudiera tener.
```
AsientoSyncService : ‚ÑπÔ∏è [Sync-Asientos] El proxy devolvi√≥ lista vac√≠a de asientos para eventoId=X
AsientoSyncService : ‚ö†Ô∏è [Sync-Asientos] Lista de asientos vac√≠a para externalId=X. Se eliminar√°n asientos locales del evento.
```

### Terminal del Proxy
Se repite siempre el mismo patr√≥n para cada request:
Seguridad ‚Üí Controller del proxy ‚Üí Servicio que habla con c√°tedra o Redis.
```
ProxyTokenAuthFilter      : üõ°Ô∏è [Seguridad] Token Bearer presente (parcial=changeme , longitud=8)
ProxyEventosResource      : üåê [Proxy] GET /api/proxy/eventos
CatServiceClient          : üéì [C√°tedra] Llamando a listarEventosCompletos v√≠a Feign
CatServiceClient          : üéì [C√°tedra] Respuesta listarEventosCompletos -> bodyLength=3585

ProxyTokenAuthFilter      : üõ°Ô∏è [Seguridad] Token Bearer presente (parcial=changeme , longitud=8)
ProxyEventosResource      : üåê [Proxy] GET /api/proxy/eventos/1/asientos
EstadoAsientosRedisService: Consultando Redis para key=evento_1, resultado=ENCONTRADO
EstadoAsientosRedisService: Se parse√≥ correctamente estado de asientos para eventoId=1 (38 asientos).

ProxyTokenAuthFilter      : üõ°Ô∏è [Seguridad] Token Bearer presente (parcial=changeme , longitud=8)
ProxyEventosResource      : üåê [Proxy] GET /api/proxy/eventos/2/asientos
EstadoAsientosRedisService: Consultando Redis para key=evento_2, resultado=NO ENCONTRADO
EstadoAsientosRedisService: No hay asientos bloqueados/vendidos para eventoId=2 (key evento_2). Devolviendo lista vac√≠a.
...

```
#Issue19
**üõ°Ô∏è [Seguridad]** Token Bearer presente (parcial=changeme , longitud=8)
- Lo escribe ProxyTokenAuthFilter.
- Significa:
  - Lleg√≥ una request a /api/proxy/**.
  - Tra√≠a header Authorization: Bearer changeme.
  - Entonces el filtro autoriza la request y permite que siga.

**üåê [Proxy]** GET /api/proxy/eventos o GET /api/proxy/eventos/1/asientos
- Log del ProxyEventosResource.
- Muestra que el request ya pas√≥ la seguridad y lleg√≥ al controller.
- Indica qu√© endpoint se est√° llamando.

**EstadoAsientosRedisService**: Consultando Redis para key=evento_1, resultado=ENCONTRADO
**EstadoAsientosRedisService**: Se parse√≥ correctamente estado de asientos para eventoId=1 (38 asientos).

- Arma la key evento_1.
- Consulta al Redis remoto de la c√°tedra.
- Loguea que la key fue encontrada (resultado=ENCONTRADO),
- Parsea el JSON de Redis ‚Üí lista de asientos (38 asientos).

**EstadoAsientosRedisService**: Consultando Redis para key=evento_2, resultado=NO ENCONTRADO
**EstadoAsientosRedisService**: No hay asientos bloqueados/vendidos para eventoId=2 (key evento_2). Devolviendo lista vac√≠a.

- Para evento_2 no existe key en Redis.
- El servicio lo interpreta como que no hay asientos bloqueados/vendidos para ese evento.
- Responde una lista vac√≠a al backend.
- proxy dice ‚Äúno tengo nada‚Äù ‚Üí backend deja al evento sin asientos locales.

üìå Y eso enlaza perfecto con lo que viste en los logs del backend:
‚ÑπÔ∏è [Sync-Asientos] El proxy devolvi√≥ lista vac√≠a...
‚ö†Ô∏è [Sync-Asientos] Lista vac√≠a... Se eliminar√°n asientos locales...

**üéì [C√°tedra]** Llamando a listarEventosCompletos v√≠a Feign
- Log de CatServiceClient / servicio que llama a la c√°tedra.
- Significa que el proxy, a su vez, est√° llamando al servidor remoto de la c√°tedra, reenviando la request.

**üéì [C√°tedra]** Respuesta listarEventosCompletos -> bodyLength=3584
- Lleg√≥ la respuesta de la c√°tedra.
- bodyLength=3584 te muestra cu√°ntos bytes devolvi√≥ (sirve para ver que vino contenido real y no un error vac√≠o).


---



## üîπ 2. Consultar eventos locales activos despu√©s de sincronizar  (#20 - #21 - #23)

### En Postman
- Backend/Evento/eventos-locales
- http://localhost:8080/api/eventos
- Devuelve: 200 OK
- JSON:
```json
[
    {
        "id": 1,
        "titulo": "but never ouch",
        "descripcion": "excepting considering brr",
        "fecha": "2025-11-13",
        "hora": "21:40",
        "organizador": "revitalise efface lounge",
        "presentadores": "bleakly culture taro",
        "cantidadAsientosTotales": 27997,
        "filaAsientos": 3968,
        "columnaAsientos": 6521,
        "activo": true
    },
    {
        "id": 1002,
        "titulo": "Otra Conferencia Nerd",
        "descripcion": "Esta es una conferencia de prueba para verificar que los datos est√°n correctos version 2",
        "fecha": "2025-12-28",
        "hora": "00:00",
        "organizador": null,
        "presentadores": null,
        "cantidadAsientosTotales": 160,
        "filaAsientos": 20,
        "columnaAsientos": 8,
        "activo": true
    },
]
```
### Que hace esta prueba?
- Explicacion Corta: 

Ac√° muestro los eventos que quedaron grabados en mi DB (Postgres) despu√©s de hablar con el proxy.
Solo aparecen los que est√°n activos, y adem√°s puede ver las filas/columnas de asientos que despu√©s uso para validar lo que llega desde Redis.

---

Esta prueba muestra c√≥mo qued√≥ la base local despu√©s de la sincronizaci√≥n de la prueba anterior:
- Lista todos los eventos activos que est√°n guardados en PostgreSQL.
    - Esto valida:
        - Que los eventos realmente se guardan/actualizan en tu BD. (#20)
        - Que el backend solo expone eventos activo = true. (#21)

- Te permite ver para cada evento sus atributos: id local (ej: 1002), titulo, descripcion, fecha, hora, filaAsientos y columnaAsientos
üëâ Estos valores son clave para el Issue #23, porque se usan para validar que los asientos que vengan de Redis est√©n dentro del rango permitido (1..filaAsientos, 1..columnaAsientos).

- Si en alg√∫n momento la c√°tedra elimina un evento:
    - la pr√≥xima sync lo marcar√° como activo = false (Issue #21),
    - y no aparecer√° m√°s en este listado /api/eventos.


### Terminal del Backend

- Indica que el backend est√° devolviendo la lista de eventos activos
```
INFO EventoResource   : [EventoResource] GET /api/eventos (devolviendo solo eventos activos) 
```


---


## üîπ 3. Simular notificaci√≥n desde proxy  (#20)

### En Postman 
- Backend/Notificaciones-Proxy/proxy-notificacion-evento
- http://localhost:8080/api/proxy/notificacion-evento
- JSON que se le pasa:
üëâ Se env√≠a este JSON solo para simular lo que mandar√≠a el proxy cuando recibe un mensaje de Kafka:
```json
{
  "eventoId": 123,
  "origen": "postman-test"
}
```
- Devuelve: 200 OK
- JSON que devuelve:
üëâ Este JSON es un ACK del backend:
- Confirma que recibi√≥ la notificaci√≥n, y que dispar√≥ internamente la sincronizaci√≥n de eventos/asientos.
```json
{
    "status": "ok",
    "mensaje": "Notificaci√≥n procesada y sincronizaci√≥n disparada"
}
```

### Que hace esta prueba?

#### Explicaci√≥n Corta

Simula la notificaci√≥n que enviar√≠a el proxy cuando Kafka detecta un cambio.
El backend recibe este JSON, lo loguea y dispara exactamente la misma sincronizaci√≥n que el endpoint /api/admin/sync-eventos.
La respuesta status: ok confirma que la notificaci√≥n fue procesada y que la sync se ejecut√≥.

#### Explicaci√≥n un poco m√°s completa

1. Postman llama a /api/proxy/notificacion-evento con un JSON que representa la notificaci√≥n.
2. El backend:

- Loguea que recibi√≥ la notificaci√≥n y su contenido.
- Llama a EventoSyncService.sincronizarEventosDesdeProxy(),
- Que a su vez:
    - Llama al proxy (GET /api/proxy/eventos).
    - Actualiza eventos en PostgreSQL.
    - Y dispara AsientoSyncService para sincronizar los asientos de cada evento.

3. En los logs ves todo ese flujo, igual que en la sincronizaci√≥n manual, pero esta vez disparado por una notificaci√≥n externa.

### Terminal del Backend
- **ProxyNotificationResource: [Proxy-Backend]**: Confirma que el endpoint /api/proxy/notificacion-evento existe y est√° activo.
- **ProxyNotificationResource: [Proxy-Backend]**: Loguea que recibi√≥ la notificaci√≥n y el JSON qu√© mand√≥ el proxy (o en este caso, Postman).

- **A partir de ac√°, el flujo es igual que en la prueba 1**:
- EventoSyncService arranca la sincronizaci√≥n.
- ProxyService llama al proxy para traer los eventos.
- Se actualizan eventos en la BD y luego se sincronizan los asientos para cada externalId:
     - se borran los asientos viejos,
     - se crean de nuevo seg√∫n la info real que devuelve la c√°tedra (v√≠a proxy y Redis).

**La diferencia clave con la prueba 1 es**:
- En la prueba 1 (Probar sincronizaci√≥n manual) la sync se dispara con /api/admin/sync-eventos.
- En esta prueba se dispara con una notificaci√≥n de proxy (/api/proxy/notificacion-evento).

- Esto demuestra que el ciclo Kafka ‚Üí Proxy ‚Üí Backend est√° listo.

```
DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
DispatcherServlet        : Completed initialization in 1 ms

ProxyNotificationResource: [Proxy-Backend] Notificaci√≥n recibida desde proxy en /api/proxy/notificacion-evento
ProxyNotificationResource: [Proxy-Backend] Body de la notificaci√≥n: {_  "eventoId": 1,_  "origen": "postman-test"_}

EventoSyncService        : üîÑ [Sync-Eventos] Iniciando sincronizaci√≥n de eventos contra proxy...
ProxyService             : üåê [Proxy-Backend] GET /eventos
ProxyService             : üì© [Proxy-Backend] Respuesta OK /eventos (bytes=3584)
EventoSyncService        : üì• [Sync-Eventos] Eventos recibidos desde proxy: 5 evento(s).

EventoSyncService        : ‚ôªÔ∏è [Sync-Eventos] Actualizando evento existente (id=1001, externalId=1) ‚Üí Conferencia Nerd
EventoSyncService        : ‚ö†Ô∏è [Sync-Eventos] El evento 1 no tiene hora en el proxy. Se asigna 00:00.
EventoSyncService        : üíæ [DB] Evento guardado ‚Üí idLocal=1001, externalId=1, titulo=Conferencia Nerd
AsientoSyncService       : üîÑ [Sync-Asientos] Iniciando sincronizaci√≥n de asientos para evento local id=1001 (externalId=1)
ProxyService             : üåê [Proxy-Backend] GET /eventos/1/asientos
ProxyService             : üì© [Proxy-Backend] Respuesta OK /eventos/1/asientos (bytes=2177)
AsientoSyncService       : üßπ [Sync-Asientos] Asientos previos eliminados para evento idLocal=1001 ‚Üí 38 asiento(s) borrado(s).
AsientoSyncService       : ‚úÖ [Sync-Asientos] Evento idLocal=1001 (externalId=1) ‚Üí Asientos sincronizados: 38 creados, 0 actualizados.

... (mismo patr√≥n para eventos 1002, 1003, 1004, 1005) ...

EventoSyncService        : ‚úÖ [Sync-Eventos] Sincronizaci√≥n de eventos finalizada correctamente.

```

### Terminal del Proxy

- Cuando llega una notificaci√≥n (simulada desde Postman), el backend dispara una sync completa, y el proxy vuelve a hablar con la c√°tedra y Redis para refrescar todo.
(misma explicacion que en la prueba 1)
```
ProxyTokenAuthFilter      : üõ°Ô∏è  [Seguridad] Token Bearer presente (parcial=changeme , longitud=8)
ProxyEventosResource      : üåê [Proxy] GET /api/proxy/eventos
CatServiceClient          : üéì [C√°tedra] Llamando a listarEventosCompletos v√≠a Feign
CatServiceClient          : üéì [C√°tedra] Respuesta listarEventosCompletos -> bodyLength=3584
ProxyTokenAuthFilter      : üõ°Ô∏è  [Seguridad] Token Bearer presente (parcial=changeme , longitud=8)
ProxyEventosResource      : üåê [Proxy] GET /api/proxy/eventos/1/asientos
EstadoAsientosRedisService: Consultando Redis para key=evento_1, resultado=ENCONTRADO
EstadoAsientosRedisService: Se parse√≥ correctamente estado de asientos para eventoId=1 (38 asientos).
ProxyTokenAuthFilter      : üõ°Ô∏è  [Seguridad] Token Bearer presente (parcial=changeme , longitud=8)
ProxyEventosResource      : üåê [Proxy] GET /api/proxy/eventos/2/asientos
EstadoAsientosRedisService: Consultando Redis para key=evento_2, resultado=ENCONTRADO
EstadoAsientosRedisService: Se parse√≥ correctamente estado de asientos para eventoId=2 (4 asientos).
... (mismo patr√≥n para eventos 3, 4 y 5) ...
```



---



## üîπ 4. Ver los asientos remotos en el proxy  (#22)
Prueba en Proxy
### En Postman
- Proxy/Asientos/asientos-por-evento
- GET http://localhost:8081/api/proxy/eventos/1/asientos
- Devuelve: 
- JSON que devuelve:
```json
{
    "asientos": [
        {
            "columna": 3,
            "estado": "Vendido",
            "expira": null,
            "fila": 2
        }, // ... otros asientos ...
    ],
    "eventoId": 1
}
```
**üëâ ¬øPor qu√© se ve este JSON as√≠?**
- **eventoId**: el ID REAL en la c√°tedra (externalId = 1).
- **asientos**: es la lista tal como la tiene Redis para ese evento:
- **fila / columna**: posici√≥n del asiento.
- **estado**: "Vendido", "Bloqueado", "Libre", etc. (formato de la c√°tedra).
- **expira**: fecha/hora ISO cuando vence el bloqueo, o null si est√° vendido o libre.

Este formato es el que despu√©s usa mi backend con los DTO:
- ProxyEstadoAsientosResponse
- ProxyAsientoDTO

### Que hace esta prueba?

### Versi√≥n corta
Llama directo al proxy para ver qu√© est√° leyendo de Redis para el evento 1.
Esto me muestra el estado de los asientos en bruto (tal cual lo entrega la c√°tedra v√≠a Redis), antes de que el backend los sincronice o los combine con la base local.‚Äù
- Esto demuestra que el proxy s√≠ est√° leyendo Redis.

## Versi√≥n un poco m√°s completa

- Comprueba que:
    - el proxy est√° levantado,
    - la seguridad funciona (pide Bearer),
    - el proxy arma la key evento_1,
    - consulta el Redis remoto de la c√°tedra,
    - y logra parsear el JSON a un objeto bien formado (eventoId + asientos[]).
- Es una prueba ‚Äúunitaria‚Äù del proxy:
- Todav√≠a no entra en juego AsientoSyncService ni la combinaci√≥n con PostgreSQL, eso se ve en la siguiente prueba 5.

### Terminal del Backend
Esta prueba no pasa por el backend, solo habla Postman ‚Üí Proxy ‚Üí Redis (c√°tedra).

### Terminal del Proxy
- Con esta prueba le muestro el eslab√≥n directo Proxy ‚Üî Redis.
- Todav√≠a no interviene el backend, es solo el proxy devolviendo tal cual lo que Redis dice que pasa en ese evento.

```bash
2025-12-11T16:56:38.740-03:00 DEBUG 188156 --- [proxy-service] [nio-8081-exec-2] a.e.u.p.config.ProxyTokenAuthFilter      : üõ°Ô∏è  [Seguridad] Token Bearer presente (parcial=eyJhbGciOiJI... , longitud=228)
2025-12-11T16:56:38.759-03:00  INFO 188156 --- [proxy-service] [nio-8081-exec-2] a.e.u.p.web.rest.ProxyEventosResource    : üåê [Proxy] GET /api/proxy/eventos/1/asientos
2025-12-11T16:56:39.979-03:00  INFO 188156 --- [proxy-service] [nio-8081-exec-2] a.e.u.p.s.EstadoAsientosRedisService     : Consultando Redis para key=evento_1, resultado=ENCONTRADO
2025-12-11T16:56:40.018-03:00  INFO 188156 --- [proxy-service] [nio-8081-exec-2] a.e.u.p.s.EstadoAsientosRedisService     : Se parse√≥ correctamente estado de asientos para eventoId=1 (38 asientos).
```



---




## üîπ 5. Ver los asientos locales ya sincronizados  (#22 - #23)

### En Postman
- Backend/Estado de Asientos (Tiempo Real)/estado-asientos-tiempo-real
- GET http://localhost:8080/api/eventos/1001/asientos
- Devuelve: 200 OK
- JSON que devuelve:
```json
[
    {
        "fila": 1,
        "columna": 1,
        "estado": "VENDIDO",
        "expiraEn": null
    }, // ... otros asientos ...
]
```

**üëâ Qu√© muestra**:
Esta prueba devuelve el mapa final de asientos que va al frontend, ya procesado por el backend:

- Cada elemento es un AsientoEstadoDTO (uno por posici√≥n Fila/Columna).
- El estado de cada asiento ya viene combinado as√≠:
    - Si en la DB (Postgres) est√° VENDIDO ‚Üí se muestra VENDIDO y se ignora Redis.
    - Si NO est√° vendido y Redis dice que est√° bloqueado vigente ‚Üí se muestra BLOQUEADO_VIGENTE con expiraEn completo.
    - Si Redis tiene un bloqueo PERO ya venci√≥ ‚Üí se considera LIBRE en el mapa final.
    - Si Redis manda asientos inv√°lidos o fuera de rango ‚Üí no se muestran, solo quedan logueados como advertencia.

Resultado de todo el flujo:
- sync de asientos (#22),
- combinaci√≥n en tiempo real con Redis (#23),
- validaciones de integridad (rangos y expiraciones).

### Que hace esta prueba?

#### Versi√≥n corta

Entra por el backend al endpoint que usa el frontend, y veo el mapa de asientos final, que combina lo que est√° en la DB (Postgres) con el estado en tiempo real que viene de Redis, aplicando las reglas de vendido, bloqueos vigentes, expirados y validaciones de rango.

#### Versi√≥n m√°s detallada

1. El backend recibe la request GET /api/eventos/1001/asientos.
2. Carga los asientos persistidos en Postgres para el evento local id=1001.
3. Llama al proxy para obtener el estado din√°mico en Redis:
GET /eventos/1/estado-asientos (donde 1 es el externalId de la c√°tedra).
4. AsientoEstadoService:
    - combina DB + Redis,
    - aplica las reglas:
        - VENDIDO manda sobre Redis,
        - bloqueo vigente / expirado,
    - aplica las validaciones de fila/columna,
    - arma la lista de AsientoEstadoDTO.
5. Te devuelve un JSON limpio, listo para que el frontend pinte la grilla.

### Terminal del Backend

- **[EventoResource]**:  Confirma que est√° llamando al endpoint correcto del backend: el que devuelve el mapa combinado para el evento 1001.
Este m√©todo internamente usa AsientoEstadoService.

- **üåê [Proxy-Backend]**: El backend llama al proxy, pero ahora al endpoint nuevo de estado en tiempo real (no al de sincronizaci√≥n completa).
Usa el externalId=1 del evento en la c√°tedra.

- **üì© [Proxy-Backend]**: El proxy respondi√≥ bien. Lleg√≥ un JSON con estado de asientos desde Redis.

- **AsientoEstadoService: ‚ö†Ô∏è [Redis]**: Estos logs vienen de AsientoEstadoService y prueban que la validaci√≥n de rangos est√° funcionando.

Se est√° evaluando cada asiento que vino en el JSON de Redis con:

boolean invalido =
    redis.getFila() == null || redis.getColumna() == null ||      // faltan datos
    redis.getFila() <= 0 || redis.getColumna() <= 0 ||            // fila/col <= 0
    redis.getFila() > evento.getFilaAsientos() ||                 // fila > filas totales del evento
    redis.getColumna() > evento.getColumnaAsientos();             // col > columnas totales del evento

En tu caso, el evento tiene columnas/filas fuera de rango, por eso se loguean con ‚ö†Ô∏è, se descartan y no se incluyen en el resultado enviado al frontend.

**‚ÄúSi Redis manda basura (asientos con fila/columna incoherente para este evento), el backend no se rompe: los detecta, los loguea como inv√°lidos y no los mezcla en el mapa final.‚Äù**

```bash
EventoResource           : [EventoResource] GET /api/eventos/1001/asientos (mapa en tiempo real)
ProxyService             : üåê [Proxy-Backend] GET /eventos/1/estado-asientos
ProxyService             : üì© [Proxy-Backend] Respuesta OK /eventos/1/estado-asientos (bytes=2177)
AsientoEstadoService     : ‚ö†Ô∏è  [Redis] Asiento remoto inv√°lido (2, 7): fuera de rango para evento idLocal=1001 (filas 1-10, columnas 1-6)
AsientoEstadoService     : ‚ö†Ô∏è  [Redis] Asiento remoto inv√°lido (5, 11): fuera de rango para evento idLocal=1001 (filas 1-10, columnas 1-6)
AsientoEstadoService     : ‚ö†Ô∏è  [Redis] Asiento remoto inv√°lido (20, 20): fuera de rango para evento idLocal=1001 (filas 1-10, columnas 1-6)
AsientoEstadoService     : ‚ö†Ô∏è  [Redis] Asiento remoto inv√°lido (21, 21): fuera de rango para evento idLocal=1001 (filas 1-10, columnas 1-6)
AsientoEstadoService     : ‚ö†Ô∏è  [Redis] Asiento remoto inv√°lido (22, 22): fuera de rango para evento idLocal=1001 (filas 1-10, columnas 1-6)
AsientoEstadoService     : ‚ö†Ô∏è  [Redis] Asiento remoto inv√°lido (23, 23): fuera de rango para evento idLocal=1001 (filas 1-10, columnas 1-6)
AsientoEstadoService     : ‚ö†Ô∏è  [Redis] Asiento remoto inv√°lido (25, 25): fuera de rango para evento idLocal=1001 (filas 1-10, columnas 1-6)
AsientoEstadoService     : ‚ö†Ô∏è  [Redis] Asiento remoto inv√°lido (26, 26): fuera de rango para evento idLocal=1001 (filas 1-10, columnas 1-6)
AsientoEstadoService     : ‚ö†Ô∏è  [Redis] Asiento remoto inv√°lido (27, 27): fuera de rango para evento idLocal=1001 (filas 1-10, columnas 1-6)
AsientoEstadoService     : ‚ö†Ô∏è  [Redis] Asiento remoto inv√°lido (28, 28): fuera de rango para evento idLocal=1001 (filas 1-10, columnas 1-6)
AsientoEstadoService     : ‚ö†Ô∏è  [Redis] Asiento remoto inv√°lido (29, 29): fuera de rango para evento idLocal=1001 (filas 1-10, columnas 1-6)
AsientoEstadoService     : ‚ö†Ô∏è  [Redis] Asiento remoto inv√°lido (30, 30): fuera de rango para evento idLocal=1001 (filas 1-10, columnas 1-6)
```

### Terminal del Proxy
```bash
ProxyTokenAuthFilter      : üõ°Ô∏è  [Seguridad] Token Bearer presente (parcial=changeme , longitud=8)
ProxyEventosResource      : üåê [Proxy] GET /api/proxy/eventos/1/estado-asientos
EstadoAsientosRedisService: Consultando Redis para key=evento_1, resultado=ENCONTRADO
EstadoAsientosRedisService: Se parse√≥ correctamente estado de asientos para eventoId=1 (38 asientos).
```



---



### üîπ 6. Ver estado de asientos desde el proxy (Redis) (#23)
Prueba en Proxy
#### En Postman
- Proxy/Asientos/estado-asientos-redis
- http://localhost:8081/api/proxy/eventos/1/estado-asientos
- Devuelve: 200 OK
- JSON que devuelve:
```json
{
    "asientos": [
        {
            "columna": 3,
            "estado": "Vendido",
            "expira": null,
            "fila": 2
        }, // ... otros asientos ...
    ], 
    "eventoId": 1
}
```
**üëâ Qu√© muestra**:
- Es el JSON directo del estado de asientos que tiene Redis para el eventoId=1, expuesta tal cual por el proxy:
- Cada elemento es un asiento con:
    - fila, columna
    - estado (Libre / Bloqueado / Vendido / Ocupado)
    - expira (si est√° bloqueado, cu√°ndo vence)
- Todav√≠a no hay combinaci√≥n con la BD local ni validaciones de rangos, esto es exactamente lo que la c√°tedra guarda en su Redis remoto.

Sirve para comparar con la prueba anterior (5):
- Esta prueba6 ‚Üí muestra el estado sin procesar (solo Redis v√≠a proxy).
- prueba5 anterior ‚Üí muestra el estado procesado (Redis + BD + validaciones).

### Que hace esta prueba?

- Ac√° no pasa por el backend. Llama directamente al proxy y veo el JSON que viene de Redis.
Esto me permite demostrar que el proxy est√° leyendo bien el Redis remoto de la c√°tedra y que el endpoint /eventos/{id}/estado-asientos funciona.

Despu√©s (en la prueba5 anterior), muestra c√≥mo el backend usa justamente este JSON para construir el mapa final de asientos.

### Terminal del Backend
En esta prueba Postman habla directo con el proxy, el backend no participa.

### Terminal del Proxy

En esta prueba pruebo directamente el eslab√≥n Redis ‚Üî Proxy.
El proxy consulta Redis con la key evento_1, encuentra datos, los parsea correctamente (39 asientos) y me los devuelve como JSON.

Ese mismo JSON es el que despu√©s usa mi backend en la prueba5 anterior para armar el mapa en tiempo real.
```bash
ProxyTokenAuthFilter      : üõ°Ô∏è  [Seguridad] Token Bearer presente (parcial=eyJhbGciOiJI... , longitud=187)
ProxyEventosResource      : üåê [Proxy] GET /api/proxy/eventos/1/estado-asientos
EstadoAsientosRedisService: Consultando Redis para key=evento_1, resultado=ENCONTRADO
EstadoAsientosRedisService: Se parse√≥ correctamente estado de asientos para eventoId=1 (39 asientos).
```

---